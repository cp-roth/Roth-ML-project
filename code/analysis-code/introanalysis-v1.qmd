---
title: "Intro Statistical Analysis Script"
author: "Cassia Roth"
date: "`r Sys.Date()`"
format: 
  html:
    code-fold: true
editor: visual
---

# Setup

```{r, message=FALSE,  warning=FALSE}
#load needed packages. make sure they are installed.
library(tidyverse) #for data processing/cleaning; includes ggplot2, tidyr, readr, dplyr, stringr, purr, forcats
library(skimr) #for nice visualization of data 
library(here) #to set paths
library(renv) #for package management
library(knitr) #for nice tables
library(kableExtra) #for nice tables
library(gt) #for nice tables
library(gtsummary) #for summary tables
library(ggplot2) #for plotting
library(tidymodels) #for modeling
library(gtExtras) # for easy summary visualization
rm(list=ls()) #clear the environment
```

Load the data

```{r}
#Path to linear data. Note the use of the here() package and not absolute paths
data_location <- here::here("data","processed-data","ML_linear.rds")
#load data
ML_linear <- readRDS(data_location)

#Path to summary data. Note the use of the here() package and not absolute paths
data_location <- here::here("data","processed-data","ML_summary.rds")
#load data
ML_summary <- readRDS(data_location)
```

# LBW and NBW percentages

First, I will see how many infants were LBW or NBW for each maternal descendant category. Then, I will perform a simple difference in means (t-test) to see if the LBW and NBW means stratified by maternal skin color are statistically significant.

```{r}
# See LBW and NBW with true denominator
LBW_percentage <- ML_summary %>%
  filter(!is.na(ModifiedColor) & !is.na(BirthweightCategory)) %>% # Remove NAs from both variables

group_by(ModifiedColor) %>% # Group by ModifiedColor
# Calculate the percentage for each group
summarise(
  total_count = n(),
  lbw_count = sum(BirthweightCategory == "LBW"),
  lbw_percentage = (lbw_count / total_count) * 100
  )

# Print the result
print(LBW_percentage)

# Perform difference in means test (t-test) for birth weight category
# Modify code to create dataset for t-test
LBW_data <- ML_summary %>%
  filter(!is.na(ModifiedColor) & !is.na(BirthweightCategory)) %>%
  mutate(is_LBW = as.numeric(BirthweightCategory == "LBW"))  # 1 if LBW, 0 if not

# Print the first few rows to check the structure
print(head(LBW_data))

# Perform t-test
t_test_result <- t.test(is_LBW ~ ModifiedColor, data = LBW_data, subset = ModifiedColor %in% c("Euro-Descent", "Afro-Descent"))

# Print the result
print(t_test_result)

# Extract specific values for inline text
p_value <- t_test_result$p.value
t_statistic <- t_test_result$statistic
df <- t_test_result$parameter
mean_diff <- diff(t_test_result$estimate)
ci_lower <- t_test_result$conf.int[1]
ci_upper <- t_test_result$conf.int[2]
```

After performing a Welch Two Sample t-test to compare the rates of LBW between Euro- and Afro-descent mothers, the results were as follows: t = `r round(t_statistic, 2)`, df = `r round(df, 1)`, p-value = `r round(p_value, digits = 3)`, mean difference = `r round(mean_diff, 4)`, 95% CI = \[`r round(ci_lower, 4)`, `r round(ci_upper, 4)`\].

# Linear Models

To be able include metrics like $(R^2)$ dynamically in the Quarto document, I first need to store the values in a list. I will create a list to store the values. In each code chunk with a fitted model, I will add the $(R^2)$ to the list. Then I can use the stored values inline in the document.

```{r}
# Create a list to store R-squared values
r_squared_values <- list()
```

I will now run a simple regression with the outcome variable (birth weight in grams) and the exposure variable maternal ancestry. I will use the recipe and workflow features of `tidymodels`.

```{r}
# Model 1 using recipes and workflows
# Define recipe for model
ML_recipe1 <- recipe(Weightgrams ~ ModifiedColor, data = ML_linear) %>% 
  step_relevel(ModifiedColor, ref_level = "Euro-Descent") %>% # Set reference level
  step_dummy(ModifiedColor) # Convert ModifiedColor to dummy variable

# Specify model
ML_spec1 <- linear_reg() %>% 
  set_engine("lm")

# Create work flow
ML_wf1 <- workflow() %>%
  add_recipe(ML_recipe1) %>%
  add_model(ML_spec1)

# Fit the work flow
ML_fit1 <- fit(ML_wf1, data = ML_linear)

# Summarize model fit with tidiers
ML_summary1 <- summary(ML_fit1) # Summary of fit
tidy(ML_fit1, conf.int = TRUE) # Coefficients and confidence intervals
model_stats1 <- glance(ML_fit1) # Extract model-level statistics

# This code is to write dynamic inline text in Quarto
# Extract R-squared value
r_squared_values$model1 <- model_stats1$r.squared

# This code is for performance measures that aren't necessary in this study
# Produce predictions for R-squared
ML_fit1_pred <- predict(ML_fit1, new_data = ML_linear %>% select(-Weightgrams))
ML_fit1_pred

# Predicted numeric outcome named .pred. Now we will match predicted values with corresponding observed outcome values
ML_fit1_pred <- bind_cols(ML_fit1_pred, ML_linear %>% select(Weightgrams))
ML_fit1_pred

# Plot observed versus predicted
plot1 <- ggplot(ML_fit1_pred, aes(x = Weightgrams, y = .pred)) +
  geom_abline(lty = 2) + # Add a dashed line to represent the 1:1 line
  geom_point(alpha = 0.5) +
  labs(x = "Observed", y = "Predicted") + #Scale and size x- and y-axis uniformly
  coord_obs_pred()
plot1

# Create metric set including RMSE and R-squared
metrics_fit1 <- metric_set(rmse, rsq)
metrics_fit1(ML_fit1_pred, truth = Weightgrams, estimate = .pred)

# Convert the output to a data frame and mutate the .estimate column to numeric
metrics_fit1 <- as.data.frame(metrics_fit1(ML_fit1_pred, truth = Weightgrams, estimate = .pred)) %>%
  mutate(.estimate = as.numeric(.estimate))
options(scipen = 999) # set opens to avoid scientific notation
metrics_fit1

# Create a gtsummary table directly from the model
table_fit1 <-
  tbl_regression(ML_fit1, exponentiate = FALSE, intercept = TRUE, show_single_row = everything()) %>% 
  bold_p() %>% # make p-values bold
  add_glance_table(include = c(r.squared, adj.r.squared, nobs)) %>%
  modify_column_unhide(columns = c(statistic, std.error))

# Print table
table_fit1

# Save regression output into table
saveRDS(table_fit1, file = here::here("results", "tables", "table_fit1.rds"))
```

Now I will run a second simple bivariate analysis, looking at infant birth weight as a function of maternal age. This time, when plotting weight as a function of maternal age, I will use a scatterplot.

```{r}
# Model Age using recipes and workflows
# Create recipe
ML_recipe_age <- recipe(Weightgrams ~ Age, data = ML_linear)

# Specify model
ML_spec_age <- linear_reg() %>% 
  set_engine("lm")

# Create work flow
ML_wf_age <- workflow() %>%
  add_recipe(ML_recipe_age) %>%
  add_model(ML_spec_age)

# Fit the work flow
ML_fit_age <- fit(ML_wf_age, data = ML_linear)

# Summarize model fit with tidiers
ML_summary_age <- summary(ML_fit_age) # Summary of fit
tidy(ML_fit_age, conf.int = TRUE) # Coefficients and confidence intervals
model_stats_age <- glance(ML_fit_age) # Extract model-level statistics

# This code is to write dynamic inline text in Quarto
# Extract R-squared value
r_squared_values$model2 <- model_stats_age$r.squared

# This code is for performance measures that aren't necessary in this study
# Produce predictions for RMSE and R-squared
ML_age_pred <- predict(ML_fit_age, new_data = ML_linear %>% select(-Weightgrams))
ML_age_pred

# Predicted numeric outcome named .pred. Now we will match predicted values with corresponding observed outcome values
ML_age_pred <- bind_cols(ML_age_pred, ML_linear %>% select(Weightgrams))
ML_age_pred

# Plot observed versus predicted
plot_age <- ggplot(ML_age_pred, aes(x = Weightgrams, y = .pred)) +
  geom_abline(lty = 2) + # Add a dashed line to represent the 1:1 line
  geom_point(alpha = 0.5) +
  labs(x = "Observed", y = "Predicted") + #Scale and size x- and y-axis uniformly
  coord_obs_pred()
plot_age

# Create metric set including RMSE and R-squared
metrics_fit_age <- metric_set(rmse, rsq)
metrics_fit_age(ML_age_pred, truth = Weightgrams, estimate = .pred)

# Convert the output to a data frame and mutate the .estimate column to numeric
metrics_fit_age <- as.data.frame(metrics_fit_age(ML_age_pred, truth = Weightgrams, estimate = .pred)) %>%
  mutate(.estimate = as.numeric(.estimate))
options(scipen = 999) # set opens to avoid scientific notation
metrics_fit_age

# Create a gtsummary table directly from the model
table_fit2 <-
  tbl_regression(ML_fit_age, exponentiate = FALSE, intercept = TRUE, show_single_row = everything()) %>% 
  bold_p() %>% 
  add_glance_table(include = c(r.squared, nobs)) %>%
  modify_column_unhide(columns = c(statistic, std.error))

#Print table
table_fit2

# Save regression output into table
saveRDS(table_fit2, file = here::here("results", "tables", "table_fit2.rds"))
```

Now I will run a slightly more complicated model that includes maternal skin color, age, nationality, and gestational status.

```{r}
# Set reference level for ModifiedColor
ML_linear$ModifiedColor <- relevel(ML_linear$ModifiedColor, ref = "Euro-Descent")

# Specify and fit model using linear_reg() (default engine, OLS) from tidymodels
ML_lm3 <- linear_reg() %>% set_engine("lm") %>% fit(Weightgrams ~ ModifiedColor + Age + ModifiedStatus + ModifiedNationality, data = ML_linear)

# Summarize model fit with tidiers
ML_lm3_summary <- summary(ML_lm3) # Summary of fit
tidy(ML_lm3, conf.int = TRUE) %>% mutate(p.value = round(p.value, 5)) # Coefficients and confidence intervals with p-values rounded to 5 decimal places
model_stats3 <- glance(ML_lm3) # extract model-level statistics

# This code is to write dynamic inline text in Quarto
# Extract R-squared value
r_squared_values$model3 <- model_stats3$r.squared

# Create a gtsummary table directly from the model
table_fit3 <- tbl_regression(ML_lm3, exponentiate = FALSE, intercept = TRUE) %>% 
  bold_p() %>% 
  add_glance_table(include = c(r.squared, adj.r.squared, nobs)) %>%
  modify_column_unhide(columns = c(statistic, std.error))
table_fit3

# Save regression output into table
saveRDS(table_fit3, file = here::here("results", "tables", "table_fit3.rds"))
```

In the first and third models, there appears to be an association between maternal skin color and infant birth weight, with Euro-descended women (the reference group) having infants with higher birth weights than Afro-descended women. In the second model, we can see that older mothers are associated with giving birth to infants with higher birth weights.

For all three models, the r-squared is small `r round(r_squared_values$model1, 3)`, `r round(r_squared_values$model2, 3)`, and `r round(r_squared_values$model3, 3)`, indicating that the model does not explain much of the variance in birth weight. This is likely due to the fact that birth weight is a complex trait influenced by many factors, including genetic, environmental, and social factors.

I am not trying to explain which general factors are trying to explain birth weight. Rather, I'm trying to understand if maternal skin color is associated with lower infant birth weight during this specific time period in Rio de Janeiro, Brazil. For example, the gestational age probably explains much of the variation in the model, yet this variable was only included in very few observations in the published clinic data from which I created this dataset.

Given my hypothesis, that the legacies of slavery affected maternal-fetal health, then maternal skin color, however, is also probably associated with premature birth, which is correlated to infant birth weight.

## Sub-Sample Modeling

There is potentially a (partial) multi-collinearity problem with maternal skin color and maternal nationality. So let's run a regression with just maternal nationality as the covariate.

```{r}
# Create a list to store R-squared values
r_squared_values2 <- list()
```

```{r}
# Model 4 sub-sample simple model
# Set reference level for Color
ML_linear$ModifiedNationality <- relevel(ML_linear$ModifiedNationality, ref = "Brazilian")

# Specify and fit model using linear_reg() (default engine, OLS) from tidymodels
ML_lm4 <- linear_reg() %>% set_engine("lm") %>% fit(Weightgrams ~ ModifiedNationality, data = ML_linear)

# Summarize model fit with tidiers
ML_lm4_summary <- summary(ML_lm4) # Summary of fit
tidy(ML_lm4, conf.int = TRUE) %>% mutate(p.value = round(p.value, 5)) # Coefficients and confidence intervals with p-values rounded to 5 decimal places
model_stats4 <- glance(ML_lm4) # Extract model-level statistics

# Extract R-squared value
r_squared_values2$model4 <- model_stats4$r.squared

# Create a gtsummary table directly from the model
table_fit4 <- tbl_regression(ML_lm4, exponentiate = FALSE, intercept = TRUE) %>% 
  bold_p() %>% 
  add_glance_table(include = c(r.squared, adj.r.squared, nobs)) %>%
  modify_column_unhide(columns = c(statistic, std.error))
table_fit4

# Save regression output into table
saveRDS(table_fit4, file = here::here("results", "tables", "table_fit4.rds"))
```

These results imply that Europeans had heavier infants than Brazilians. Since all women of color in this sample were Brazilian, there is a problem with multicollinearity. So I will perform some subsample modeling to understand this issue. We will create a `Brazilian` (yes, no) variable, drop all non-Brazilians from the study, and run the original regression with the covariates.

```{r}
# Create dummy variables for new category of Brazilian or not
# Create dummy variables for status and change to English
ML_linear <- mutate(ML_linear, 
                    Brazilian = recode_factor(ModifiedNationality, 
                                              "European" = "Non-Brazilian",
                                              "Middle Eastern" = "Non-Brazilian",
                                              "Latin American" = "Non-Brazilian",
                                              "Brazilian" = "Brazilian"))

# Check the structure of the updated data frame
str(ML_linear)

# Save ML_Linear as RDS
save_data_location <- here::here("data","processed-data","ML_linear.rds")
saveRDS(ML_linear, file = save_data_location)
```

Now, I will run a regression with only this new variable.

```{r}
# Model 5 sub-sample simple model
# Set reference level for Brazilian
ML_linear$Brazilian <- relevel(ML_linear$Brazilian, ref = "Brazilian")

# Specify and fit model using linear_reg() (default engine, OLS) from tidymodels
ML_lm5 <- linear_reg() %>% set_engine("lm") %>% fit(Weightgrams ~ Brazilian, data = ML_linear)

# Summarize model fit with tidiers
ML_lm5_summary <- summary(ML_lm5) # Summary of fit
tidy(ML_lm5, conf.int = TRUE) %>% mutate(p.value = round(p.value, 5)) # Coefficients and confidence intervals with p-values rounded to 5 decimal places
model_stats5 <- glance(ML_lm5) # Extract model-level statistics

# Extract R-squared value
r_squared_values2$model5 <- model_stats5$r.squared

# Create a gtsummary table directly from the model
table_fit5 <- tbl_regression(ML_lm5, exponentiate = FALSE, intercept = TRUE) %>% 
  bold_p() %>% 
  add_glance_table(include = c(r.squared, adj.r.squared, nobs)) %>%
  modify_column_unhide(columns = c(statistic, std.error))
table_fit5

# Save regression output into table
saveRDS(table_fit5, file = here::here("results", "tables", "table_fit5.rds"))
```

Here, non-Brazilians had babies on average weighing 100 grams more than Brazilians (p-value 0.001). So I will now run a regression of only Brazilian women using `Afro-Descent` and `Euro-descent` categories.

```{r}
# Filter data based on desired conditions
filtered_data <- ML_linear %>%
  filter(Brazilian == "Brazilian")

# Model 6 sub-sample simple linear model
# Set reference level for "Euro-descent"
ML_linear$ModifiedColor <- relevel(ML_linear$ModifiedColor, ref = "Euro-Descent")

# Specify and fit model using linear_reg() (default engine, OLS) from tidymodels
ML_lm6 <- linear_reg() %>% set_engine("lm") %>% fit(Weightgrams ~ ModifiedColor, data = filtered_data)

# Summarize model fit with tidiers
ML_lm6_summary <- summary(ML_lm6) # Summary of fit
tidy(ML_lm6, conf.int = TRUE) %>% mutate(p.value = round(p.value, 5)) # Coefficients and confidence intervals with p-values rounded to 5 decimal places
model_stats6 <- glance(ML_lm6) # Extract model-level statistics

# Extract R-squared value
r_squared_values2$model6 <- model_stats6$r.squared

# Create a gtsummary table directly from the model
table_fit6 <- tbl_regression(ML_lm6, exponentiate = FALSE, intercept = TRUE) %>% 
  bold_p() %>% 
  add_glance_table(include = c(r.squared, adj.r.squared, nobs)) %>%
  modify_column_unhide(columns = c(statistic, std.error))
table_fit6

# Save regression output into table
saveRDS(table_fit6, file = here::here("results", "tables", "table_fit6.rds"))
```

The $R^2$ for these models were `r round(r_squared_values2$model4, 3)`, `r round(r_squared_values2$model5, 3)`, and `r round(r_squared_values2$model6, 3)`.

## Multivariate analysis

Moving on from issues of collinearity, I will run a model where skin color is differentiated according to the original data, or with three categories (White, Black, and Mixed Race). I'll start with a simple model of infant birth weight as a function of maternal skin color. Then I will run a model with all the predictors.

```{r}
# Create a list to store R-squared values
r_squared_values3 <- list()
```

```{r}
# Model 7 simple linear model
# Set reference level for Color
ML_linear$Color <- relevel(ML_linear$Color, ref = "White")

# Specify and fit model using linear_reg() (default engine, OLS) from tidymodels
ML_lm7 <- linear_reg() %>% set_engine("lm") %>% fit(Weightgrams ~ Color, data = ML_linear)

# Summarize model fit with tidiers
ML_lm7_summary <- summary(ML_lm7) # Summary of fit
tidy(ML_lm7, conf.int = TRUE) %>% mutate(p.value = round(p.value, 5)) # Coefficients and confidence intervals with p-values rounded to 5 decimal places
model_stats7 <- glance(ML_lm7) # Extract model-level statistics

# Extract R-squared value
r_squared_values3$model7 <- model_stats7$r.squared

# Create a gtsummary table directly from the model
table_fit7 <- tbl_regression(ML_lm7, exponentiate = FALSE, intercept = TRUE) %>% 
  bold_p() %>% 
  add_glance_table(include = c(r.squared, adj.r.squared, nobs)) %>%
  modify_column_unhide(columns = c(statistic, std.error))
table_fit7

# Save regression output into table
saveRDS(table_fit7, file = here::here("results", "tables", "table_fit7.rds"))

# Complex linear model
# Set reference level for Color
ML_linear$Color <- relevel(ML_linear$Color, ref = "White")

# Specify and fit model using linear_reg() (default engine, OLS) from tidymodels
ML_lm8 <- linear_reg() %>% set_engine("lm") %>% fit(Weightgrams ~ Color + Age + ModifiedStatus + ModifiedNationality, data = ML_linear)

# Summarize model fit with tidiers
ML_lm8_summary <- summary(ML_lm8) # Summary of fit
tidy(ML_lm8, conf.int = TRUE) %>% mutate(p.value = round(p.value, 5)) # Coefficients and confidence intervals with p-values rounded to 5 decimal places
model_stats8 <- glance(ML_lm8) # Extract model-level statistics

# Extract R-squared value
r_squared_values3$model8 <- model_stats8$r.squared

# Create a gtsummary table directly from the model
table_fit8 <- tbl_regression(ML_lm8, exponentiate = FALSE, intercept = TRUE) %>% 
  bold_p() %>% 
  add_glance_table(include = c(r.squared, adj.r.squared, nobs)) %>%
  modify_column_unhide(columns = c(statistic, std.error))
table_fit8

# Save regression output into table
saveRDS(table_fit8, file = here::here("results", "tables", "table_fit8.rds"))
```

The $R^2$ for these models were `r round(r_squared_values3$model7, 3)` and `r round(r_squared_values3$model8, 3)`.

## Logistic models

Now I will still consider `Birthweight` as the outcome of interest, but I will use the dummy variable created in the `eda-v1.qmd` file that categorizes infant birth weight into normal birth weight (NBW $>2500$ g) or low birth weight (LBW $\leq2500$ g) and fit a logistic model, using the main predictor of interest, `ModifiedColor`.

First, I will split data into training and testing sets to later calculate ROC_AUC.

```{r}
# Check factor levels
levels(ML_linear$BirthweightCategory) # Reference is LBW, so need to change

# Set the reference level explicitly to NBW
ML_linear <- ML_linear %>%
  mutate(BirthweightCategory = relevel(BirthweightCategory, ref = "NBW"))

#set seed
set.seed(123)
ML_log_split <- initial_split(ML_linear, prop = 0.75, strata = BirthweightCategory)

# Create training and test datasets
ML_log_train <- training(ML_log_split)
ML_log_test <- testing(ML_log_split)
```

Now I will run the first logistic model with `ModifiedColor` as the predictor.

```{r}
# Create recipe
# Logistic model 1: Create recipe simple logistic model (creating dummy variables and standardizing continuous variables)
log1_recipe <- recipe(BirthweightCategory ~ ModifiedColor, data = ML_linear) #%>%
  #step_dummy(all_nominal(), -all_outcomes()) %>%
  #step_normalize(all_predictors())

# Define model specification
log1_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Create workflow
log1_wf <- workflow() %>%
  add_recipe(log1_recipe) %>%
  add_model(log1_spec)

# Fit model
log1_fit <- log1_wf %>%
fit(data = ML_linear)

# Extract fitted model from workflow
log1_fitted <- extract_fit_parsnip(log1_fit)$fit

# Create a gtsummary table directly from the model
table_log1 <- tbl_regression(log1_fitted, exponentiate = TRUE) %>% # use exponentiate true for ORs
  bold_p(t = 0.05) %>%
  modify_table_styling(
    columns = label,
    rows = label == "ModifiedColor",
    text_format = "bold"
  )
table_log1

# Save regression output into table
saveRDS(table_log1, file = here::here("results", "tables", "table_log1.rds"))

# Calculate performance metrics using pseudo-R2
# Extract model metrics using broom
model_metrics1 <- glance(log1_fitted)

# Calculate McFadden's R-squared
# McFadden's R-squared = 1 - (deviance(model) / deviance(null model))
mcfadden_r2_1 <- 1 - (model_metrics1$deviance / model_metrics1$null.deviance)

# Print McFadden's R-squared
print(mcfadden_r2_1)

# Calculate performance metrics using ROC_AUC
# Fit the model on the training data
log1_fit <- log1_wf %>% fit(data = ML_log_train)

# Predict probabilities on the test set
prob_preds1 <- predict(log1_fit, new_data = ML_log_test, type = "prob")

# Combine predictions with true values
results1 <- bind_cols(ML_log_test, prob_preds1)

# Calculate ROC-AUC
roc_auc_result1 <- roc_auc(results1, truth = BirthweightCategory, .pred_LBW)

# Print ROC-AUC
print(roc_auc_result1)

# Create and plot the ROC curve
roc_curve_data1 <- roc_curve(results1, truth = BirthweightCategory, .pred_LBW)

# Plotting the ROC curve
roc_plot1 <- ggplot(roc_curve_data1, aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 2) +
  labs(title = "ROC Curve",
       x = "1 - Specificity",
       y = "Sensitivity")

# Print the plot
print(roc_plot1)

# Store metrics in a list for dynamic inline text
logistic_model_metrics1 <- list(
  pseudo_r_squared = mcfadden_r2_1,
  auc = roc_auc_result1$.estimate
)
```

Then, I will create a list of lists to store my performance metrics for dynamic inline text later.

```{r}
# Create a list to store performance metrics
all_logistic_models <- list()
all_logistic_models$model1 <- logistic_model_metrics1
```

With an ROC_AUC of `r round(all_logistic_models$model1$auc, 3)`, the model is performing worse than random guessing. The pseudo-$R^2$ is `r round(all_logistic_models$model1$pseudo_r_squared, 3)`.

Now I will run another logistic model with `Color` as the predictor.

```{r}
# Logistic model 2: simple logistic regression model with Color as predictor
# Check factor levels
levels(ML_linear$BirthweightCategory) # Reference is LBW

# Set the reference level explicitly to NBW
ML_linear <- ML_linear %>%
  mutate(BirthweightCategory = relevel(BirthweightCategory, ref = "NBW"))

# Create recipe
# Create recipe simple logistic model (creating dummy variables and standardizing continuous variables)
log2_recipe <- recipe(BirthweightCategory ~ Color, data = ML_linear) #%>%
  #step_dummy(all_nominal(), -all_outcomes()) %>%
  #step_normalize(all_predictors())

# Define model specification
log2_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Create workflow
log2_wf <- workflow() %>%
  add_recipe(log2_recipe) %>%
  add_model(log2_spec)

# Fit model
log2_fit <- log2_wf %>%
fit(data = ML_linear)

# Extract fitted model from workflow
log2_fitted <- extract_fit_parsnip(log2_fit)$fit

# Create a gtsummary table directly from the model
table_log2 <- tbl_regression(log2_fitted, exponentiate = TRUE) %>% # use exponentiate true for ORs
  bold_p(t = 0.05) %>%
  modify_table_styling(
    columns = label,
    rows = label == "Color",
    text_format = "bold"
  )
table_log2

# Save regression output into table
saveRDS(table_log2, file = here::here("results", "tables", "table_log2.rds"))

# Extract model metrics using broom
model_metrics2 <- glance(log2_fitted)

# Calculate McFadden's R-squared
# McFadden's R-squared = 1 - (deviance(model) / deviance(null model))
mcfadden_r2_2 <- 1 - (model_metrics2$deviance / model_metrics2$null.deviance)

# Print McFadden's R-squared
print(mcfadden_r2_2)

# Calculate performance metrics using ROC_AUC
# Fit the model on the training data
log2_fit <- log2_wf %>% fit(data = ML_log_train)

# Predict probabilities on the test set
prob_preds2 <- predict(log2_fit, new_data = ML_log_test, type = "prob")

# Combine predictions with true values
results2 <- bind_cols(ML_log_test, prob_preds2)

# Calculate ROC-AUC
roc_auc_result2 <- roc_auc(results2, truth = BirthweightCategory, .pred_LBW)

# Print ROC-AUC
print(roc_auc_result2)

# Create and plot the ROC curve
roc_curve_data2 <- roc_curve(results2, truth = BirthweightCategory, .pred_LBW)

# Plotting the ROC curve
roc_plot2 <- ggplot(roc_curve_data2, aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 2) +
  labs(title = "ROC Curve",
       x = "1 - Specificity",
       y = "Sensitivity")

# Print the plot
print(roc_plot2)

# Store metrics in a list for dynamic inline text
logistic_model_metrics2 <- list(
  pseudo_r_squared = mcfadden_r2_1,
  auc = roc_auc_result1$.estimate
)
all_logistic_models$model2 <- logistic_model_metrics2 # add to list of lists
```

The ROC_AUC for the second simple logistic regression model is `r round(all_logistic_models$model2$auc, 3)`, or still worse than random guessing. The pseudo- $R^2$ is `r round(all_logistic_models$model2$auc, 3)`.

Now, I will run two more logistic models, one with `ModifiedColor` and the other covariates `Age`, `ModifiedStatus`, `ModifiedNationality`, and one with `Color` and these same covariates.

```{r}
# Logistic model 3: Multiple logistic regression model with ModifiedColor as the predictor
# Check factor levels
levels(ML_linear$BirthweightCategory) # Reference is LBW
levels(ML_linear$ModifiedColor) # Reference is Euro-descent
levels(ML_linear$ModifiedStatus) # Reference is multiparous
levels(ML_linear$ModifiedNationality) # Reference is European

# Set the reference level explicitly to NBW
ML_linear <- ML_linear %>%
  mutate(BirthweightCategory = relevel(BirthweightCategory, ref = "NBW"),
         ModifiedNationality = relevel(ModifiedNationality, ref = "Brazilian"))

# Create recipe
# Create recipe simple logistic model (creating dummy variables and standardizing continuous variables)
log3_recipe <- recipe(BirthweightCategory ~ ModifiedColor + Age + ModifiedStatus + ModifiedNationality, data = ML_linear) #%>%
  #step_dummy(all_nominal(), -all_outcomes()) %>%
  #step_normalize(all_predictors())

# Define model specification
log3_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Create workflow
log3_wf <- workflow() %>%
  add_recipe(log3_recipe) %>%
  add_model(log3_spec)

# Fit model
log3_fit <- log3_wf %>%
fit(data = ML_linear)

# Extract fitted model from workflow
log3_fitted <- extract_fit_parsnip(log3_fit)$fit

# Create a gtsummary table directly from the model
table_log3 <- tbl_regression(log3_fitted, exponentiate = TRUE) # use exponentiate true for ORs
table_log3 <- bold_p(table_log3, t = 0.05)
table_log3

# Save regression output into table
saveRDS(table_log3, file = here::here("results", "tables", "table_log3.rds"))

# Calculate metrics using pseudo-R2
# Extract model metrics using broom
model_metrics3 <- glance(log3_fitted)

# Calculate McFadden's R-squared
# McFadden's R-squared = 1 - (deviance(model) / deviance(null model))
mcfadden_r2_3 <- 1 - (model_metrics3$deviance / model_metrics3$null.deviance)

# Print McFadden's R-squared
print(mcfadden_r2_3)

# Calculate performance metrics using ROC_AUC
# Fit the model on the training data
log3_fit <- log3_wf %>% fit(data = ML_log_train)

# Predict probabilities on the test set
prob_preds3 <- predict(log3_fit, new_data = ML_log_test, type = "prob")

# Combine predictions with true values
results3 <- bind_cols(ML_log_test, prob_preds3)

# Calculate ROC-AUC
roc_auc_result3 <- roc_auc(results3, truth = BirthweightCategory, .pred_LBW)

# Print ROC-AUC
print(roc_auc_result3)

# Create and plot the ROC curve
roc_curve_data3 <- roc_curve(results3, truth = BirthweightCategory, .pred_LBW)

# Plotting the ROC curve
roc_plot3 <- ggplot(roc_curve_data3, aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 2) +
  labs(title = "ROC Curve",
       x = "1 - Specificity",
       y = "Sensitivity")

# Print the plot
print(roc_plot3)

# Store metrics in a list for dynamic inline text
logistic_model_metrics3 <- list(
  pseudo_r_squared = mcfadden_r2_1,
  auc = roc_auc_result1$.estimate
)
all_logistic_models$model3 <- logistic_model_metrics3 # add to list of lists
```

The ROC_AUC here is `r round(all_logistic_metrics$model3$auc, 3)`, still worse than random guessing. The pseudo-$R^2$ is `r round (all_logistic_metrics$model3$pseudo_r_squared, 3)`.

```{r}
# Logistic model 4: Multiple logistic regression model with Color as the predictor
# Check factor levels
levels(ML_linear$BirthweightCategory) # Reference is LBW
levels(ML_linear$Color) # Reference is White
levels(ML_linear$ModifiedStatus) # Reference is multiparous
levels(ML_linear$ModifiedNationality) # Reference is European

# Set the reference level explicitly to NBW
ML_linear <- ML_linear %>%
  mutate(BirthweightCategory = relevel(BirthweightCategory, ref = "NBW"),
         ModifiedNationality = relevel(ModifiedNationality, ref = "Brazilian"))

# Create recipe
# Create recipe simple logistic model (creating dummy variables and standardizing continuous variables)
log4_recipe <- recipe(BirthweightCategory ~ Color + Age + ModifiedStatus + ModifiedNationality, data = ML_linear) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_normalize(all_predictors())

# Define model specification
log4_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Create workflow
log4_wf <- workflow() %>%
  add_recipe(log4_recipe) %>%
  add_model(log4_spec)

# Fit model
log4_fit <- log4_wf %>%
fit(data = ML_linear)

# Extract fitted model from workflow
log4_fitted <- extract_fit_parsnip(log4_fit)$fit

# Create a gtsummary table directly from the model
table_log4 <- tbl_regression(log4_fitted, exponentiate = TRUE) # exponentiate true for ORs

#Bold significant p-values
table_log4 <- bold_p(table_log4, t = 0.05)
table_log4

# Save regression output into table
saveRDS(table_log4, file = here::here("results", "tables", "table_log4.rds"))

# Calculate metrics using pseudo-R2
# Extract model metrics using broom
model_metrics4 <- glance(log4_fitted)

# Calculate McFadden's R-squared
# McFadden's R-squared = 1 - (deviance(model) / deviance(null model))
mcfadden_r2_4 <- 1 - (model_metrics4$deviance / model_metrics4$null.deviance)

# Print McFadden's R-squared
print(mcfadden_r2_4)

# Calculate performance metrics using ROC_AUC
# Fit the model on the training data
log4_fit <- log4_wf %>% fit(data = ML_log_train)

# Predict probabilities on the test set
prob_preds4 <- predict(log4_fit, new_data = ML_log_test, type = "prob")

# Combine predictions with true values
results4 <- bind_cols(ML_log_test, prob_preds4)

# Calculate ROC-AUC
roc_auc_result4 <- roc_auc(results4, truth = BirthweightCategory, .pred_LBW)

# Print ROC-AUC
print(roc_auc_result4)

# Create and plot the ROC curve
roc_curve_data4 <- roc_curve(results4, truth = BirthweightCategory, .pred_LBW)

# Plotting the ROC curve
roc_plot4 <- ggplot(roc_curve_data4, aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 2) +
  labs(title = "ROC Curve",
       x = "1 - Specificity",
       y = "Sensitivity")

# Print the plot
print(roc_plot4)

# Store metrics in a list for dynamic inline text
logistic_model_metrics4 <- list(
  pseudo_r_squared = mcfadden_r2_1,
  auc = roc_auc_result1$.estimate
)
all_logistic_models$model4 <- logistic_model_metrics4 # add to list of lists
```

In the final model, the ROC_AUC is `r round(all_logistic_metrics$model4$auc, 3)` still worse than random guessing. The pseudo-$R^2$ is `r round(all_logistic_metrics$model4$pseudo_r_squared, 3)`.

# Merge unadjusted log models 1 and 2

```{r}
# Combine the two tables using tbl_stack for unadjusted ORs
table5 <- tbl_stack(list(table_log1, table_log2), group_header = c()) %>%
  as_gt() %>%
  gt::tab_style(style = gt::cell_text(weight = "bold"),
  locations = gt::cells_row_groups(groups = everything()))
table5

# Save regression output into table
saveRDS(table5, file = here("results", "tables", "table5_final.rds"))
```

# Predominant and residual distributions

```{r}
# Calculate the mean and standard deviation of the predominant distribution
predominant_stats <- ML_summary %>% 
   filter(!is.na(Weightgrams)) %>% #filter out NAs
  summarize(
    mean_weight = mean(Weightgrams),
    sd_weight = sd(Weightgrams)
  )

# Determine the range of the predominant distribution
predominant_lower <- predominant_stats$mean_weight - 2 * predominant_stats$sd_weight
predominant_upper <- predominant_stats$mean_weight + 2 * predominant_stats$sd_weight

# Calculate the proportion of observations in the predominant distribution
predominant_proportion <- ML_summary %>%
  filter(Weightgrams >= predominant_lower & Weightgrams <= predominant_upper) %>%
  nrow() / nrow(ML_summary)

# Calculate the proportion of observations in the residual distribution
residual_proportion <- 1 - predominant_proportion

# Print the results
cat("Predominant distribution:\n")
cat("Mean:", predominant_stats$mean_weight, "grams\n")
cat("Standard deviation:", predominant_stats$sd_weight, "grams\n")
cat("Proportion:", predominant_proportion, "\n\n")

cat("Residual distribution:\n")
cat("Proportion:", residual_proportion, "\n")

# Plot the distribution
residual_plot_all <- ML_summary %>% filter(!is.na(Weightgrams)) %>% #filter out NAs
  ggplot(aes(x = Weightgrams)) +
  geom_density(fill="#69b3a2", color="#e9ecef") +
  stat_function(fun = dnorm, args = list(mean = predominant_stats$mean_weight, sd = predominant_stats$sd_weight), color = "black", linewidth = 0.5) +
  labs(
    title = "Birth Weight Distribution for All Births, Maternidade Laranjeiras, 1922-1926",
    x = "Birth Weight (g)"
  ) +
  theme_ipsum() +
  theme(plot.title = element_text(size=12))
plot(residual_plot_all)

# Save plot to file
figure_file = here("results","figures","residual_plot_all.png")
ggsave(filename = figure_file, plot=residual_plot_all, bg="white") #background is white

# Calculate two distributions: Afro and Euro
# Calculate the mean and standard deviation of the predominant distribution Afro
predominant_stats_afro <- ML_summary %>% 
   filter(!is.na(WeightgramsAfro)) %>% #filter out NAs
  summarize(
    mean_weight_afro = mean(WeightgramsAfro),
    sd_weight_afro = sd(WeightgramsAfro)
  )

# Determine the range of the predominant distribution
predominant_lower_afro <- predominant_stats_afro$mean_weight_afro - 2 * predominant_stats_afro$sd_weight_afro
predominant_upper_afro <- predominant_stats_afro$mean_weight_afro + 2 * predominant_stats_afro$sd_weight_afro

# Calculate the proportion of observations in the predominant distribution
predominant_proportion_afro <- ML_summary %>%
  filter(WeightgramsAfro >= predominant_lower_afro & WeightgramsAfro <= predominant_upper_afro) %>%
  nrow() / nrow(ML_summary)

# Calculate the proportion of observations in the residual distribution
residual_proportion_afro <- 1 - predominant_proportion_afro

# Print the results
cat("Predominant distribution:\n")
cat("Mean:", predominant_stats_afro$mean_weight_afro, "grams\n")
cat("Standard deviation:", predominant_stats_afro$sd_weight_afro, "grams\n")
cat("Proportion:", predominant_proportion_afro, "\n\n")

cat("Residual distribution:\n")
cat("Proportion:", residual_proportion_afro, "\n")

# Calculate the mean and standard deviation of the predominant distribution Euro
predominant_stats_euro <- ML_summary %>% 
   filter(!is.na(WeightgramsEuro)) %>% #filter out NAs
  summarize(
    mean_weight_euro = mean(WeightgramsEuro),
    sd_weight_euro = sd(WeightgramsEuro)
  )

# Determine the range of the predominant distribution
predominant_lower_euro <- predominant_stats_euro$mean_weight_euro - 2 * predominant_stats_euro$sd_weight_euro
predominant_upper_euro <- predominant_stats_euro$mean_weight_euro + 2 * predominant_stats_euro$sd_weight_euro

# Calculate the proportion of observations in the predominant distribution
predominant_proportion_euro <- ML_summary %>%
  filter(WeightgramsEuro >= predominant_lower_euro & WeightgramsEuro <= predominant_upper_euro) %>%
  nrow() / nrow(ML_summary)

# Calculate the proportion of observations in the residual distribution
residual_proportion_euro <- 1 - predominant_proportion_euro

# Print the results
cat("Predominant distribution:\n")
cat("Mean:", predominant_stats_euro$mean_weight_euro, "grams\n")
cat("Standard deviation:", predominant_stats_euro$sd_weight_euro, "grams\n")
cat("Proportion:", predominant_proportion_euro, "\n\n")

cat("Residual distribution:\n")
cat("Proportion:", residual_proportion_euro, "\n")

# Plot both distributions
residual_plot_divided <- ML_summary %>% 
  filter(!is.na(WeightgramsAfro) | !is.na(WeightgramsEuro)) %>% #filter out NAs
  ggplot() +
  geom_density(aes(x = WeightgramsAfro), fill = "#69b3a2", alpha = 0.5, color = NA) +
  geom_density(aes(x = WeightgramsEuro), fill = "#404080", alpha = 0.5, color = NA) +
  stat_function(fun = dnorm, 
        args = list(mean = predominant_stats_afro$mean_weight_afro,
                sd = predominant_stats_afro$sd_weight_afro),
                color = "black", linewidth = 0.5) +
  stat_function(fun = dnorm, 
                args = list(mean = predominant_stats_euro$mean_weight_euro, 
                            sd = predominant_stats_euro$sd_weight_euro), 
                color = "black", linewidth = 0.5) +
  labs(
    title = "Birth Weight Distribution for Afro- and Euro-Descended Infants",
    subtitle = "Maternidade Laranjeiras, 1922-1926",
    x = "Birth Weight (g)",
    fill = "Infant Descent"
  ) +
  scale_x_continuous(limits = c(1000, 5000), breaks = seq(1000, 5000, by = 1000)) +
  theme_ipsum() +
  theme(plot.title = element_text(size=12),
        plot.subtitle = element_text(size=10),
        legend.position = "bottom")
plot(residual_plot_divided)

# Save plot to file
figure_file = here("results","figures","residual_plot_divided.png")
ggsave(filename = figure_file, plot=residual_plot_divided, bg="white") #background is white
```
